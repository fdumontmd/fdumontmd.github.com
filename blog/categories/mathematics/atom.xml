<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Mathematics | Wakatta!]]></title>
  <link href="http://blog.wakatta.jp/blog/categories/mathematics/atom.xml" rel="self"/>
  <link href="http://blog.wakatta.jp/"/>
  <updated>2012-01-14T15:50:18+09:00</updated>
  <id>http://blog.wakatta.jp/</id>
  <author>
    <name><![CDATA[Frédéric Dumont]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Concrete Mathematics Repertoire Method]]></title>
    <link href="http://blog.wakatta.jp/blog/2012/01/14/concrete-mathematics-repertoire-method/"/>
    <updated>2012-01-14T13:33:00+09:00</updated>
    <id>http://blog.wakatta.jp/blog/2012/01/14/concrete-mathematics-repertoire-method</id>
    <content type="html"><![CDATA[<p>The repertoire method is never really explained in the book, or
anywhere else I could find on the Internet. There are a couple of
posts on this subject, so I though I should add mine.</p>

<p>The repertoire method is really a tool to help with the intuitive step
of figuring out a closed formula for a recurrence equation. It does so
by breaking the original problem into smaller parts, with the hope
they might be easier to solve.</p>

<!-- more -->


<h3>Why it works</h3>

<p>Let's assume we have a system of recurrence equations with parameters,
so that the unknown function can be expressed as a linear combination
of other (unknown) functions where the coefficients are the parameters:</p>

<div markdown="0">
\begin{align}
g(1) &amp; = b(0, \alpha_1, \cdots, \alpha_m)\\\\
g(n) &amp; = r_n(g_1, \cdots, g_{n-1}, \alpha_1, \cdots, \alpha_m)\\\\
&amp; = \sum_{i=1}^m A_i(n)\alpha_i,
\end{align}
</div>


<p>We can consider $g$ as a specific point in a $m$-dimensional function
space (determined by both the recurrence equations, and the
parameters), and because $g$ is a linear combination, we can try to
find $m$ base functions (hopefully known or easy to compute)
$f_k(n) = \sum_{i=1}^m A_i(n)\alpha_{i_k}$ with $1 \le k \le m$, expressed in
terms of $m$ linearly independent vectors
$(\alpha_{1_k},\cdots,\alpha_{m_k})$.</p>

<p>In other words, if we can find $m$ linearly independent parameter
vectors such that, for each, we have a known solution $f_k(n)$, then
we can express the function $g$ as a linear combination of $f_k(n)$
for any parameters (because the $m$ $f_k(n)$ form a base for the
$m$-dimensional function space defined by the recurrence equations).</p>

<h3>How it works</h3>

<p>First, we need to check that the recurrence equations accept a
solution expressed as</p>

<div markdown="0">
\begin{align}
g(n) &amp; = \sum_{i=1}^m A_i(n)\alpha_i
\end{align}
</div>


<p>It is enough to plug this definition into the recurrence equations,
and make sure the different parameters always remain in different
terms.</p>

<p>Then we can either solve $f(n) = \sum_{i=1}^m A_i(n)\alpha_i$ for
known $f(n)$, or for known $\alpha_i$
parameters, as long as we end up with $m$ linearly independent
parameter vectors (or, as it is equivalent, $m$ linearly independent
known functions for specific parameters).</p>

<p>It is important to keep in mind that a solution can be searched from
both direction: either set a function and try to solve for the
parameters, or set the parameters and solve for the function.</p>

<h3>Homework exercise</h3>

<p>Given</p>

<div markdown="0">
\begin{align}
g(1) &amp; = \alpha\\\\
g(2n+j) &amp; = 3g(n) + \gamma n + \beta_j&amp;&amp;\text{for \(j=0, 1\) and \(n \gt 1 \)}\\\\
\end{align}
</div>


<p>We need to check that $g$ can be written as</p>

<div markdown="0">
\begin{align}
g(n) &amp; = \alpha A(n) + \beta_0 B_0(n) + \beta_1 B_1(n) + \gamma C(n)\\\\
\end{align}
</div>


<p>The base case is trivial. The recurrence case is</p>

<div markdown="0">
\begin{align}
g(2n) &amp; = 3g(n) + \gamma n + \beta_0\\\\
&amp; = 3(\alpha A(n) +  \beta_0 B_0(n) + \beta_1 B_1(n) + \gamma C(n)) + \gamma n \beta_0\\\\
&amp; = \alpha 3A(n) + \beta_0 (3 B_0(n) + 1) + \beta_1 3B_1(n) + \gamma (3C(n) + n)\\\\
g(2n+1) &amp; = 3g(n) + \gamma n + \beta_1\\\\
&amp; = 3(\alpha A(n) +  \beta_0 B_0(n) + \beta_1 B_1(n) + \gamma C(n)) + + \gamma n\beta_1\\\\
&amp; = \alpha 3A(n) + \beta_0 3 B_0(n)+ \beta_1 (3B_1(n) + 1) + \gamma (3C(n) + n)\\\\
\end{align}
</div>


<p>so $g$ can be expressed as a linear combination of other functions,
with the parameters as the coefficients.</p>

<p>Now, when I tried to solve this problem, I didn't know I could set the
parameters to values that would lead to an easy solution ($\gamma = 0$
turns the problem into an easy to solve generalised radix-based
Josephus problem); instead I wasted a lot of time trying to find known
functions and solve for the parameters, which is why I have four steps
below instead of just two as in the book.</p>

<h4>$g(n) = n$</h4>

<p>As the book suggests, I tried to solve for $g(n) = n$:</p>

<div markdown="0">
\begin{align}
1 = g(1) &amp; = \alpha&amp;&amp;\alpha = 1\\\\
2n = g(2n) &amp; = 3g(n) + \gamma n + \beta_0\\\\
&amp; = 3n + \gamma n + \beta_0&amp;&amp;\gamma = -1, \beta_0 = 0\\\\
2n+1 = g(2n+1) &amp; = 3g(n) + \gamma n + \beta_1\\\\
&amp; = 3n - n + \beta_1&amp;&amp; \beta_1 = 1\\\\
\end{align}
</div>


<h4>$g(2^m+l) = 3^m$</h4>

<p>As the recurrence equation looks like the generalised radix-based
Josephus equation, I tried to solve for $g(2^m+1) = 3^m$:</p>

<div markdown="0">
\begin{align}
1 = g(1) &amp; = \alpha&amp;&amp;\alpha = 1\\\\
3^m = g(2^m+2l) &amp; = 3g(2^{m-1}+l) + \gamma (2^{m-1} + l) + \beta_0\\\\
&amp; = 3\cdot 3^{m-1} + \gamma (2^{m-1} + l) + \beta_0&amp;&amp; \beta_0, \gamma = 0\\\\
3^m = g(2^m+2l+1) &amp; = 3g(2^{m^1}+l) + \gamma (2^{m-1} + l) + \beta_1\\\\
&amp; = 3\cdot 3^{m-1}&amp;&amp;\beta_1 = 0\\\\
\end{align}
</div>


<h4>$g(n) = 1$</h4>

<p>I tried to solve for $g(n) = 1$, as it seemed useful to solve for a
constant (no linear combination of linearly independent non-constant
functions can produce a constant function).</p>

<div markdown="0">
\begin{align}
1 = g(1) &amp; = \alpha&amp;&amp; \alpha = 1\\\\
1 = g(2n+j) &amp; = 3g(n) + \gamma n + \beta_j\\\\
&amp; = 3 + \gamma n + \beta_j&amp;&amp; \gamma = 0, \beta_j = -2\\\\
\end{align}
</div>


<h4>$\alpha, \beta_1 = 1, \beta_0,  \gamma = 0$</h4>

<p>This is the step that took me the longest, and when I finally
understood I could fix the parameters, I was able to use the
radix-based Josephus solution.</p>

<p>The recurrence equations</p>

<div markdown="0">
\begin{align}
g(1) &amp; = 1\\\\
g(2n) &amp; = 3g(n)\\\\
g(2n+1) &amp; = 3g(n) + 1\\\\
\end{align}
</div>


<p>have as solution $g(2^m + (b_m\cdots b_0)) = 3^m + (b_m\cdots b_0)_3$.</p>

<h4>Solving for $g(n)$</h4>

<p>We have the equations</p>

<div markdown="0">
\begin{align}
A(n) - C(n) &amp; = n\\\\
A(2^m + l) &amp; = 3^m\\\\
A(n) -2(B_0(n) + B_1(n)) &amp; = 1\\\\
B_1(2^m+l) &amp; = h_3(l)&amp;&amp;\text{where \(h_3(b_m\cdots b_0) = (b_m\cdots b_0)_3\)}\\\\
\end{align}
</div>


<p>We have two functions already defined ($A(n)$ and $B_1(n)$), and the
other two equations give us the remaining function.</p>

<p>Now we can solve for $g(n)$:</p>

<div markdown="0">
\begin{align}
g(2^m+l) &amp; = \alpha 3^m + \beta_0 (\frac{3^m - 1}{2} - h_3(l)) + \beta_1 h_3(l) + \gamma (3^m + h_3(l) - 2^m - l)
\end{align}
</div>


<p>The $\gamma$ term is really $h_3(n) - n$.</p>

<p>The $\beta_0$ term is the same as $h_3(2^m-1-l)$, as can be seen by
observing that in base $3$, $3^m$ is $1$ followed by $m$ zeroes, so
$3^m-1$ is $m$ twos, and $\frac{3^m-1}{2}$ is $m$ ones, in other words
the same representation as the binary representation of $2^m-1$.</p>

<p>Now, the binary representation of $l$ is the same as the
representation in base $3$ of $h_3(l)$ (by definition of $h_3$), so
the binary representation of $2^m-1-l$ is the same as the
representation in base $3$ of $\frac{3^m-1}{2} - h_3(l)$.</p>

<p>With these two observations, it is possible to rewrite $g$ as</p>

<div markdown="0">
\begin{align}
g(1b_m\cdots b_0) &amp; = (\alpha\beta_{b_m}\cdots\beta_{b_0})_3 + \gamma ((1b_m\cdots b_0)_3 - (1b_m\cdots b_0)_2)
\end{align}
</div>


<p>which is the book solution.</p>

<h3>Faster solution</h3>

<p>It is enough to solve for
$\alpha, \beta_0, \beta_1 \ne 0, \gamma = 0$,
and to find the parameters for $g(n) = n$. The first gives $A$,
$B_0$ and $B_1$ directly by the generalised radix-based Josephus
solution, and the second one adds a constraint to solve for $C$ as well.</p>

<h3>Wrapping up</h3>

<p>As can be seen above, approaching the problem from both directions
(solving for known functions and solving for known parameters) can
result in time saved, and simplified expression of the solution.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Concrete Mathematics Chapter 1 Homework Exercises Part 2]]></title>
    <link href="http://blog.wakatta.jp/blog/2012/01/14/concrete-mathematics-chapter-1-homework-exercises-part-2/"/>
    <updated>2012-01-14T12:14:00+09:00</updated>
    <id>http://blog.wakatta.jp/blog/2012/01/14/concrete-mathematics-chapter-1-homework-exercises-part-2</id>
    <content type="html"><![CDATA[<p>I finally finished the homework exercises.</p>

<!-- more -->


<h2>Homework Exercises Part 2</h2>

<h3>Generalized Tower of Hanoi</h3>

<p>To solve this, I first observed that for $n=1$, we need $m_1$ moves,
and for $n \gt 1$, we need
$A(m_1, \cdots, m_{n-1}) + m_n + A(m_1, \cdots, m_{n-1})$ or
$2A(m_1, \cdots, m_{n-1}) + m_n$ moves.</p>

<p>This leads to the solution,</p>

<div markdown="0">
\begin{align}
A(m_1, \cdots, m_n) &amp;= \sum_{i=1}^n m_i 2^{n-i}\\\\
\end{align}
</div>


<p>which is trivially shown by induction. The base case:</p>

<div markdown="0">
\begin{align}
A(m_1) &amp; = \sum_{i=1}^1 m_i 2^{1-i}\\\\
&amp; = m_1 2^0\\\\
&amp; = m_1
\end{align}
</div>


<p>And for larger $n$, assuming
$A(m_1, \cdots, m_n) = \sum_{i=1}^n m_i 2^{n-i}$,</p>

<div markdown="0">
\begin{align}
A(m_1, \cdots, m_{n+1}) &amp; = 2A(m_1, \cdots, m_n) +
m_{n+1}&amp;&amp;\text{by definition}\\\\
&amp; = 2\sum_{i=1}^n m_i 2^{n-i} + m_{n+1}&amp;&amp;\text{induction hypothesis}\\\\
&amp; = \sum_{i=1}^{n} m_i 2^{n+1-i} + m_{n+1} 2^{0}\\\\
&amp; = \sum_{i=1}^{n+1} m_i 2^{n+1-i}\\\\
\end{align}
</div>


<h3>Zig-zag lines</h3>

<p>A geometric problem, but very similar to the previous intersecting
lines. A zig-zag is made of 3 segments, so a pair of zig-zag lines can
intersect at 9 different points. The first zig-zag line defines two
regions; each new zig-zag adds a new region, plus one more for each
intersection point.</p>

<p>This gives the following recurrence equations:</p>

<div markdown="0">
\begin{align}
ZZ_1 &amp; = 2\\\\
ZZ_n &amp; = ZZ_{n-1} + 9(n-1) + 1\\\\
\end{align}
</div>


<p>Using the linearity of the recurrence equation, it is easy to see that</p>

<div markdown="0">
\begin{align}
ZZ_n &amp; = ZZ_1 + 9S_{n-1} + (n-1)
\end{align}
</div>


<p>Here I used the linearity to compute solutions to both
$ZZ_n = ZZ_{n-1} + 9(n-1)$ and $ZZ_n = ZZ_{n-1} + 1$, which are
equally trivial. Then I combined the solutions into one.</p>

<p>I use (again) induction to confirm the solution. The base case is
$ZZ_1 = ZZ_1 + 9S_0 + 0$. And for other $n$, assuming
$ZZ_n = ZZ_1 + 9S_{n-1} + (n-1)$</p>

<div markdown="0">
\begin{align}
ZZ_{n+1} &amp; = ZZ_{n} + 9n + 1&amp;&amp;\text{by definition}\\\\
&amp; = ZZ_1 + 9S_{n-1} + (n-1) + 9n + 1&amp;&amp;\text{induction hypothesis}\\\\
&amp; = ZZ_1 + 9(S_{n-1} + n) + (n-1+1)\\\\
&amp; = ZZ_1 + 9S_n + n
\end{align}
</div>


<p>The formula can also be written as</p>

<div markdown="0">
\begin{align}
ZZ_n &amp; = \frac{9n^2-7n+2}{2}
\end{align}
</div>


<h3>Planes cutting cheese</h3>

<p>Again, a geometric problem. This one gave me more trouble. It
took me a while before finally seeing that a new plane intersection
with the previous ones will be a set of intersecting lines which
defines the regions the new plan will divide in two.</p>

<p>The number of regions formed by intersecting lines was solved in the
book, and defined as $L_n = S_n + 1$</p>

<p>So a plane cutting $n$ existing planes will define
$P_{n+1} = P_n + L_n$
new regions. This recurrence gives $P_5 = 26$ regions.</p>

<p>The book did not expect a closed formula for this exercise, as the
necessary techniques are only covered in chapter 5.</p>

<h3>Josephus co-conspirator</h3>

<p>The recurrence equation for $I(n)$ follow the structure of $J(n)$, but
with different base cases:</p>

<div markdown="0">
\begin{align}
I(2) &amp; = 2&amp;&amp;\text{\(I(1)\) is not defined}\\\\
I(2n) &amp; = 2I(n) - 1\\\\
I(2n+1) &amp; = 2I(n) + 1
\end{align}
</div>


<p>Here I generated the first few values to get inspired. I noticed that
$I(n)$ had increasing odd values for batches that were longer than for
$J(n)$: $3, 6, 12, 24, \cdots$.</p>

<p>These numbers are from the series $3\cdot 2^m$, so using the same
"intuitive" step as in the book, I tried to show that
$I(3\cdot 2^m + l) = 2l + 1$ with $0 \le l \lt 3\cdot 2^m$
(the formula does not work for $I(2)$, which has to be defined separately).</p>

<p>By induction on $m$: the base case is $I(3) = I(3\cdot 2^0 + l) = 1$.</p>

<p>Assuming $I(3\cdot 2^m + l) = 2l+1$, we have</p>

<div markdown="0">
\begin{align}
I(3\cdot2^{m+1} + 2l) &amp; = 2I(3\cdot 2^m + l) -1&amp;&amp;\text{by definition}\\\\
&amp;= 2(2l+1) -1&amp;&amp;\text{induction hypothesis}\\\\
&amp;= 4l+2-1\\\\
&amp;= 2(2l)+1\\\\
I(3\cdot 2^{m+1} + (2l+ 1)) &amp; = 2I(3\cdot 2^m + l) + 1&amp;&amp;\text{by definition}\\\\
&amp; = 2(2l+1) + 1&amp;&amp;\text{induction hypothesis}\\\\
\end{align}
</div>


<p>The book solution is defined in terms of $2^m+2^{m-1}+k$, which is
same:</p>

<div markdown="0">
\begin{align}
2^m+2^{m-1}+k &amp; = 2\cdot 2^{m-1} + 2^{m-1} + k\\\\
&amp; = 3\cdot 2^{m-1} + k
\end{align}
</div>


<p>with $1 \le m$, while I have $0 \le m$.</p>

<h3>Repertoire method</h3>

<p>I put the repertoire method in its own
<a href="/blog/2012/01/14/concrete-mathematics-repertoire-method/">post</a> as it
was both the most difficult exercise and the one where I learned the most.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Concrete Mathematics Chapter 1 Homework Exercises Part 1]]></title>
    <link href="http://blog.wakatta.jp/blog/2012/01/09/concrete-mathematics-chapter-1-homework-exercises-part-1/"/>
    <updated>2012-01-09T20:23:00+09:00</updated>
    <id>http://blog.wakatta.jp/blog/2012/01/09/concrete-mathematics-chapter-1-homework-exercises-part-1</id>
    <content type="html"><![CDATA[<p>I am working my way through the homework exercises, and so far I have
had more success than with the warmups. Here's what I have solved so far.</p>

<!--more-->


<h2>Homework Exercises</h2>

<h3>Basic recurrence</h3>

<p>This one was fairly simple, so simple that I wasted one hour trying to
improve the solution.</p>

<p>Just computing the first few terms of the sequence:</p>

<div markdown="0">
\begin{align}
Q_0 &amp; = \alpha \\\\
Q_1 &amp; = \beta \\\\
Q_2 &amp; = \frac{1+\beta}{\alpha}\\\\
Q_3 &amp; = \frac{1+\alpha+\beta}{\alpha\beta}\\\\
Q_4 &amp; = \frac{\alpha\left( 1 + \alpha + \alpha\beta + \beta\right)}{\alpha\beta(1+\beta)}\\\\
&amp; = \frac{(1+\alpha)(1+\beta)}{\beta(1+\beta)}\\\\
&amp; = \frac{1+\alpha}{\beta}\\\\
Q_5 &amp; = \frac{\alpha\beta\left(1+\alpha+\beta \right)}{\beta \left( 1+\alpha+\beta \right)}\\\\
&amp; = \alpha\\\\
Q_6 &amp; = \frac{\beta\left( 1+\alpha \right)}{1+\alpha}\\\\
&amp; = \beta
\end{align}
</div>


<p>So the sequence is cyclic. I tried to find a closed formula, but the
book does not go that far, and it is unlikely to be possible.</p>

<h3>Product of averages</h3>

<h4>$P(n)$ implies $P(n-1)$</h4>

<p>First of all, I checked that nothing fishy was going on with the
selection of a particular $x_n$, but if $P(n)$ is true, then it is
true for every $x_1\cdots x_n$ set, and in particular for one with a
specific $x_n$.</p>

<p>So nothing fishy is going on.</p>

<p>Assuming the given value for $x_n$, we have</p>

<div markdown="0">
\begin{align}
\left( \frac{x_1 + \cdots + x_n}{n} \right)^n &amp; = \left( \frac{x_1 + \cdots + x_{n-1} + \frac{x_1+\cdots+x_{n-1}}{n-1}}{n}\right)^n\\\\
&amp; = \left( \frac{(n-1)x_1 + \cdots + (n-1)x_{n-1}+x_1+\cdots + x_{n-1}}{n(n-1)}\right)^n\\\\
&amp; = \left( \frac{n(x_1+\cdots+x_{n-1})}{n(n-1)}\right)^n\\\\
&amp; = \left( \frac{x_1+\cdots+x_{n-1}}{n-1}\right)^n\\\\
&amp; = x_n^n
\end{align}
</div>


<p>So, assuming $P(n)$, we have</p>

<div markdown="0">
\begin{align}
x_1\cdots x_{n-1}x_n &amp;\le x_n^n\\\\
x_1\cdots x_{n-1} &amp;\le x_n^{n-1}\\\\
x_1\cdots x_{n-1} &amp;\le \left( \frac{x_1+\cdots+x_{n-1}}{n-1}\right)^{n-1}&amp;&amp;\text{i.e. $P(n-1)$}
\end{align}
</div>


<h4>$P(n)$ and $P(2)$ implies $P(2n)$</h4>

<div markdown="0">
\begin{align}
x_1\cdots x_{2n} &amp; = x_1\cdots x_{n}x_{n+1}\cdots x_{2n}&amp;&amp;\text{associativity}\\\\
&amp; \le \left(\frac{x_1+\cdots+x_n}{n}\right)^n \left(\frac{x_{n+1}+\cdots+x_{2n}}{n}\right)^n&amp;&amp;\text{applying $P(n)$ twice}\\\\
&amp; = \left( \frac{x_1+\cdots+x_n}{n}\frac{x_{n+1}+\cdots+x_{2n}}{n}\right)^n\\\\
&amp; \le \left( \left(\frac{\frac{x_1+\cdots+x_n}{n} + \frac{x_{n+1}+\cdots+x_{2n}}{n}}{2} \right)^2\right)^n&amp;&amp;\text{applying $P(2)$}\\\\
&amp; = \left( \frac{x_1+\cdots+x_n+x_{n+1}+\cdots+x_{2n}}{2n}\right)^{2n}&amp;&amp;\text{i.e. $P(2n)$}\\\\
\end{align}
</div>


<h4>$P(n) \forall n \ge 1$</h4>

<p>The case for $P(1)$ is trivial, and $P(2)$ is already proven. We have
$P(n)$ implies $P(n-1)$ and $P(n)$ implies $P(2n)$.</p>

<p>One first approach is to use the basic induction step: we have $P(1)$,
$P(2)$, and we need $P(n) \implies P(n+1)$.</p>

<p>But $P(n) \implies P(2n) \implies P(2n-1) \implies \cdots \implies
P(2n-(n-1))$. The last one is $P(n1+)$, so the induction step holds.</p>

<p>Alternatively, we can show that to prove $P$ for a given $n$, we need
to prove $P$ for a smaller value. As naturals have a minimum, we must
eventually rely on $P(2)$, which would prove the whole chain.</p>

<p>To see this, for $n \ge 3$, if $n = 2m$, we need to prove $P(m)$; if
$n = 2m+1$, we need to prove $P(2m+2)$, which is implied by $P(m+1)$.</p>

<p>So, $\forall n \ge 3, \exists m \lt n \mid P(m) \implies P(n)$. That
with the base cases is enough to establish $P(n) \forall n$.</p>

<h3>Clockwise Tower of Hanoi</h3>

<p>First, both $Q_0$ and $R_0$ are trivial.</p>

<p>Then, to move $n$ discs from $A$ to $B$, you need to move $n-1$ discs
from $A$ to $C$ (counter-clockwise), then move one disc from $A$ to
$B$, then move the $n-1$ discs from $C$ to $B$ (again,
counter-clockwise).</p>

<p>This means $Q_n = R_{n-1} + 1 + R_{n-1} = 2R_{n-1} + 1$.</p>

<p>The case for $R_n$ is a bit more complex. My first (flawed) attempt
was to observe that to move $n$ discs from $B$ to $A$, you could move
them from $B$ to $C$, then $C$ to $A$. In other words,</p>

<div markdown="0">
\begin{align}
R_n &amp; \ge 2Q_n\\\\
&amp; = Q_n + 2R_{n-1} + 1&amp;&amp;\text{Replacing one \(Q_n\) by \(2R_{n-1}+1\)}\\\\
&amp; = Q_n + 4Q_{n-1} + 1&amp;&amp;\text{Replacing \(R_{n-1}\) by \(2Q_{n-1}\)}\\\\
\end{align}
</div>


<p>But the $4Q_{n-1}$ means moving the stack of $n-1$ discs $4$ times,
which is the same as moving it just one time (as $3$ times bring it
back to its original position).</p>

<p>So we're left with just $Q_n + Q_{n-1} + 1$. But as I said, this
reasoning is flawed, as it mixes the count of moves with the effect of
moves (where $3$ moves are the same as $0$ move).</p>

<p>While it is possible to repair this reasoning by introducing special
operators that take two parameters (the number of discs, and the
number of steps), it is simpler to try and express $R_n$ strictly in
terms $n-1$ stacks and $1$ disc moves.</p>

<p>So, to move $n$ discs from $B$ to $A$, you need to move $n-1$ discs
from $B$ to $A$ (counter-clockwise), then one disc from $B$ to $C$
(clockwise), then the $n-1$ discs from $A$ to $B$ (clockwise), then
one disc from $C$ to $A$ (clockwise), then finally the $n-1$ discs
from $B$ to $A$ (counter-clockwise).</p>

<p>Or,</p>

<div markdown="0">
\begin{align}
R_n &amp;= R_{n-1} + 1 + Q_{n-1} + 1 + R_{n-1}\\\\
&amp; = 2R_{n-} + 1 + Q_{n-1} + 1\\\\
&amp; = Q_n + Q_{n-1} + 1&amp;&amp;\text{definition of \(Q_n\)}\\\\
\end{align}
</div>


<p>As the recurrence is expressed (initially) only in terms of necessary
moves of strictly smaller stacks, there is no risk of hiding moves
that are equivalent to no moves (as in my first attempt), so the
equation is the minimum number of moves.</p>

<h3>Double Tower of Hanoi</h3>

<h4>Basic Problem</h4>

<p>First, notice we should keep each pair together, because otherwise
they would block larger discs from moving. So each pair of move should
be used to relocate a pair of identical discs to another peg. So we
should expect to need twice as many moves as the original tower.</p>

<p>More precisely, with $A(n)$ the number of moves required to solve a
$2n$ Double Tower of Hanoi, we have:</p>

<div markdown="0">
\begin{align}
(1) &amp; = 2\\\\
A(n) &amp; = A(n-1) + 2 + A(n-1)\\\\
&amp; = 2A(n-1) + 2\\\\
\end{align}
</div>


<p>Using $A(n) + 2= U(n)$, we get</p>

<div markdown="0">
\begin{align}
U(1) &amp; = 4\\\\
U(n) &amp; = 2U(n-1)\\\\
&amp; 2^{n+1}\\\\
A(n) &amp; = 2^{n+1} -2\\\\
     &amp; = 2(T_n)\\\\
\end{align}
</div>


<h4>Order Preserving</h4>

<p>If we consider all the $2n$ discs as different, then in $T_{2n}=2^{2n}-1$
moves, we can recreate the same order as the original.</p>

<p>Of course, we can do better. It is enough to move each pair an even
number of times: the first time will switch their order; the second
one will restore it, ...</p>

<p>This is similar to the warmup problem where we cannot move any disc
directly between any two pegs, so using the same constraint to move
any pair would get us to the target order in less than $2\cdot 3^n-1$.</p>

<p>But there is still a better way.</p>

<p>A $2$ discs problem needs exactly $3$ moves.  And the $4$ discs
problem will require just $11$ moves, rather than the $18$ that the
above formula predicts.</p>

<p>A wild guess: the number of moves is $4(2^n-1)-1$.</p>

<p>In trying to solve (or even write) the recurrence equation, it is
important to keep in mind that several ways to move the discs, each
with its own count, will be used.</p>

<p>We know we need two pairs of moves to relocate the two bottom discs
while keeping the order (assuming there are other discs). In doing so,
we will move the next two discs an even number of times, requiring
another 2 times to keep their order. So as long as we make sure the
last operation has the right (even) number of moves, we do not need to
keep this constraint on the other operations.</p>

<p>To recap: we need to move the last pair of discs $2$ times. So we first move
the $n-1$ pairs to a peg, then move the last pair to the other peg,
then the $n-1$ pairs to the first peg, then the last pair to the last
peg. At this stage, the $n-1$ discs have move an even number of times,
so their in the right order, even if we used the non order preserving
solution that was computed above (requiring $2T_{n-1}$ moves).</p>

<p>At this stage, a bit of notation should clarify:</p>

<div markdown="0">
\begin{align}
B(1) &amp; = 3\\\\
B(n) &amp; = A(n-1) + 2 + A(n-1) + 2 + B(n-1)\\\\
&amp; = 2T_{n-1} + 2 + 2T_{n-1} + 2 + B(n-1)\\\\
&amp; = 4T_{n-1}+4+B(n-1)\\\\
\end{align}
</div>


<p>Trying to prove the guess above:</p>

<div markdown="0">
\begin{align}
B(1) &amp; = 4(2^1-1) - 1\\\\
&amp; = 3\\\\
B(n) &amp; = 4(2^{n-1} -1) + 4 + B(n-1)\\\\
&amp; = 4\cdot 2^{n-1} + 4(2^{n-1} - 1) -1\\\\
&amp; = 4\cdot 2^n -4 -1\\\\
&amp; = 4(2^n-1)-1
\end{align}
</div>


<p>So the guess was right. It can also be rewritten as</p>

<div markdown="0">
\begin{align}
4(2^n-1)-1 &amp = 4\cdot 2^n - 4 -1\\\\
&amp; = 2^{n+2} - 5\\\\
\end{align}
</div>


<p>which is the book solution.</p>

<p>This being a bonus exercise, I currently experience an intense, although
pointless, sense of pride and achievement.</p>

<p>No doubt the other exercises will cut me down to size.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Concrete Mathematics Chapter 1 Warmups]]></title>
    <link href="http://blog.wakatta.jp/blog/2012/01/07/concrete-mathematics-chapter-1-warmups/"/>
    <updated>2012-01-07T19:09:00+09:00</updated>
    <id>http://blog.wakatta.jp/blog/2012/01/07/concrete-mathematics-chapter-1-warmups</id>
    <content type="html"><![CDATA[<p>It took me far longer than it should have, and I had a very partial
success; I guess my excuse is that my brain was still cold...</p>

<p>At least I can claim I did try to solve all the exercises; I really
spent hours on this.</p>

<!--more-->


<h2>Warmups</h2>

<h3>Horse colour</h3>

<p>I kind of botched this one, as I tried to answer it even before
reading the chapter... and my first instinct was that such a use of
induction (taking numbered subsets) was invalid.</p>

<p>Of course it is not. This is a perfectly valid approach, but, as the
book states, in the present case it breaks down for $n=2$.</p>

<p>Properly expressed with math notation, it becomes clear that the
``same colour'' concept is a binary relation (a reflexive, symmetric
and transitive one). The key is <em>binary</em>: if every pair of horses were
the same colour, then induction could be used.</p>

<h3>Tower of Hanoi Variation</h3>

<p>The description in the book is somewhat confusing, as it states the
restriction in terms of absolute positions (that is, no direct move
between left peg and right peg), rather than relative (if you want to
move a disc between peg $A$ and peg $B$, you must first move it to peg $C$,
then to peg $B$).</p>

<p>The first approach does not work (that is, it is impossible to solve
the problem under these conditions), but obviously the authors meant
the second approach.</p>

<h4>Number of moves</h4>

<p>This variation can be solved using the exact same tools as the
original problem.</p>

<p>Assuming we want to move a stack from $A$ to $B$, using $C$ as
transfer peg: a single disc can be moved in $2$ steps ($A$ to $C$, $C$
to $B$); to move more than $1$, you first need to move the $n-1$ from
$A$ to $B$, then move $1$ disk from $A$ to $C$, move the $n-1$ discs
from $B$ back to $A$, move the one disc from $C$ to $B$, and finally
move the $n-1$ discs from $A$ to $B$.</p>

<p>More concisely:</p>

<div markdown="0">
$$
\begin{align}
T_1 &amp;= 2&amp;&amp;\text{base case}\\\\
T_n &amp;= T_{n-1} + 1 + T_{n-1} + 1 + T_{n-1}\\\\
&amp; = 3T_{n-1} + 2&amp;&amp;\text{recurrence equation}
\end{align}
$$
</div>


<p>Using the exact same method as in the book, let's define
$T_n + 1= U_n$:</p>

<div markdown="0">
$$
\begin{align}
U_1 &amp;= T_1 + 1\\\\
&amp; = 3\\\\
U_n &amp;= T_n + 1\\\\
&amp; = 3(U_{n-1} -1) + 3\\\\
&amp; = 3U_{n-1} - 3 + 3\\\\
&amp; = 3U_{n-1}
\end{align}
$$
</div>


<p>Then, $U_n = 3^n$, and $T_n = 3^n-1$.</p>

<h4>Arrangements</h4>

<p>As discs must be sorted, to describe an arrangement it is enough to
list the peg for each disc. As there are $3$ pegs, this means
there are $3^n$ different arrangements.</p>

<p>The variation takes $3^n-1$ moves, but counting the starting position
as well, this means $3^n$ different positions, which is the same as
the total number of arrangements.</p>

<h3>Tower of Hanoi, Initial Setup Variation</h3>

<p>Once again, by induction: to move a disk to peg $B$:</p>

<p><em>Base case</em>: moving the smallest disc takes at most $1$ move ($0$ if
it is already on peg $B$), so $T_1 \le 1$;
<em>Recurrence</em>: to move the disc of size $n$, assuming it is on $A$, we
need to move all the smaller discs to $C$ (to clear both $A$ and $B$),
then move the disc of size $n$, and finally move all the smaller discs
to $B$. Calling the clearing operation $Cl_n$, we have
$T_n \le Cl_{n-1} + 1 + T_{n-1}$.</p>

<p>A moment of thought is enough to realise that $Cl_n$ amounts to the
same operation as $T_n$ (that is, move each disc to a specific peg,
no matter where it currently is), so we have $Cl_n = T_n$, and
therefore $T_n \le 2T_{n-1} + 1$, which is the same recurrence equation
as the original problem.</p>

<p>Therefore there is no position that is more that $2^n-1$ moves from
the target position.</p>

<h3>Venn Diagram with 4 circles</h3>

<p>I completely failed to solve this one, even though I spent most of the
time on this problem alone. I had the intuition that it could not be
done; I also found that the maximum number of regions would be 14, but
not matter what I tried, I could not prove it.</p>

<p>I tried to use Geometry, hoping that a minimal list of constraints on
the circles would prove that some of the regions that should be
restricted to two circles were in fact always covered by three or
more.</p>

<p>Eventually, when I gave up and looked at the solution, I still could not
understand it. So a circle can only intersect another one in at most 2
points. OK, so what?</p>

<p>After more research (the Google kind, this time), I found
<a href="http://www.brynmawr.edu/math/people/anmyers/PAPERS/Venn.pdf">this paper</a>
which explains why. Each intersection point creates a single new
region. Although once again I have no intuition I can trust in this
domain, in this case the reasoning seems similar enough to
intersecting lines that I feel somewhat confident.</p>

<p>So the above observation gives a recurrence equation:</p>

<div markdown="0">
$$
\begin{align}
C_1 &amp;= 2\\\\
C_n &amp;= C_{n-1} + 2(n-1)
\end{align}
$$
</div>


<p>Already, we have that $C_4 = 14$, which is less than the required
$16$ for a Venn diagram (and according to this
<a href="http://www.combinatorics.org/Surveys/ds5/VennEJC.html">document</a>),
four circles form a <em>Euler diagram</em>, not a Venn diagram.</p>

<p>Clearly a triangular number sequence is hiding in there. The
recurrence equations above can be rewritten as</p>

<div markdown="0">
$$
\begin{align}
C_n &amp;= 2+\sum_{i=1}^{n}2(i-1)\\\\
&amp;= 2+2\sum_{i=0}^{n-1}i\\\\
&amp;= 2+2\frac{n(n-1)}{2}\\\\
&amp;= n^2-n+2
\end{align}
$$
</div>


<h3>Bounded Regions in the Plane</h3>

<p>Another one where my intuition for Geometry completely failed me. I
had a correct start, identifying that each new line intersecting the
existing ones at $k$ points could at best create $k-1$ new bounded
regions, but when I try to check this I fumbled.</p>

<p>Yet the reason it simple: a line intersecting 2 others will either
define a bounded triangle, or cut an existing bounded region in two.</p>

<p>The new bounded regions are not made of arbitrary triple of lines, but
are next to each others in the plane; really this is similar to the
fence problem. So a line cutting $k$ other lines will create at best
$k-1$ new bounded region. The equality is achieved if there are no
parallel lines, and all the intersection points are distinct.</p>

<p>As the book observes, each new line will also add two new unbounded
regions (the original problem had that a new line would create
$k+1$ new regions).</p>

<p>Once again, the triangular number sequence is not far:</p>

<div markdown="0">
$$
\begin{align}
B_i &amp; = 0 &amp;&amp\text{for $1 \\le i \\lt 3$}\\\\
B_3 &amp; = 1\\\\
B_n &amp; = B_{n-1} + n - 2\\\\
&amp; = \sum_{i=2}^{n} i-2\\\\
&amp; = \sum_{i=0}^{n-2} i\\\\
&amp; = \frac{(n-1)(n-2)}{2}\\\\
&amp; = S_{n-2}
\end{align}
$$
</div>


<h3>Invalid Recurrence</h3>

<p>The recurrence for $H$ has a number of problems. The one I found is
that it only establishes the induction hypothesis for going from an
even number to an odd one; nothing can be said for going from an odd
number to an even one (and indeed, the hypothesis breaks then).</p>

<p>As the book mentions, another problem is the base case, which is
incompatible with the induction hypothesis.</p>

<h3>Wrapping up</h3>

<p>I spent way too much time on these exercises, but most of it was on
exercises with a geometric nature: I could not find an algebraic
description of these problems that would be suitable for the kind of
treatment this chapter is about. But once I had the equations, I was
able to solve the problems without trouble.</p>

<p>Next, the homework exercises.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Concrete Mathematics Chapter 1 Notes]]></title>
    <link href="http://blog.wakatta.jp/blog/2012/01/06/concrete-mathematics-chapter-1-notes/"/>
    <updated>2012-01-06T13:52:00+09:00</updated>
    <id>http://blog.wakatta.jp/blog/2012/01/06/concrete-mathematics-chapter-1-notes</id>
    <content type="html"><![CDATA[<p>For the first post of this hopefully long series, I have a few notes I
wrote down as I was reading Chapter 1. Nothing revolutionary, but it
gives me a chance to play with math notation.</p>

<!--more-->


<h1>Lines in the Plane</h1>

<p>I must admit that my memories of Geometry are far, far away (the
subject was not addressed at all when I studied Mathematics at
university, and I had no need for Geometry in my work since), so I
spent perhaps an unreasonable amount of time to check the validity of
the most elementary steps.</p>

<p>It goes without saying that the exercises of a Geometric nature are
particularly challenging (as if I needed the extra difficulty).</p>

<h2>Intersecting lines</h2>

<p>The notion that one line will add $k$ new regions if it intersects
other lines at $k-1$ points is due to the fact that $k-1$ distinct
lines define at least $k$ regions (more if they are not all parallel),
and one more line that intersects them all will divide these $k$
regions in two.</p>

<h1>Josephus Problem</h1>

<h2>$J(5 \cdot 2^m) = 2^{m+1} + 1$</h2>

<p>This is based on the fact that $J(10) = 5$ and $J(2n) = 2J(n) -1$.</p>

<p>By induction:</p>

<p><em>Base case</em>: it is true for $m = 1$: $J(5\cdot 2) = J(10) = 5 =
2^{1+1} + 1$</p>

<p><em>Recurrence</em>: assuming it is true for $m$,</p>

<div markdown="0">
$$
\begin{align}
J(5\cdot 2^{m+1}) &amp;= J(2(5\cdot 2^m))\\\\
&amp;= 2J(5\cdot 2^m) - 1&amp;&amp;\text{as $J(2n) = 2J(n) -1$}\\\\
&amp;= 2(2^{m+1}+1) - 1&amp;&amp;\text{induction hypothesis}\\\\
&amp;= 2\cdot 2^{m+1} + 2 - 1\\\\
&amp;= 2^{m+2} + 1
\end{align}
$$
</div>


<h2>$A(2^{m}+l) = 2^{m}$</h2>

<p>It took me a while to convince myself that the $l$ was not a problem
here. This can be seen by considering $l$ in binary notation, and
using $A(2n) = 2A(n)$ and $A(2n+1) = 2A(n)$ to remove the rightmost
bit.</p>

<p>That is, with $2^m > l = (b_{m-1}b_{m-2}\cdots b_{1}b_{0})_2$,we have:</p>

<div markdown="0">
$$
\begin{align}
A(2^{m}+l) &amp;= A(2^{m}+(b_{m-1}b_{m-2}\cdots b_{1}b_{0})_2)\\\\
&amp;= 2A(2^{m-1}+(b_{m-1}b_{m-2}\cdots b_{1})_2)\\\\
&amp;= 2^{2}A(2^{m-2}+(b_{m-1}b_{m-2}\cdots b_{2})_2)\\\\
&amp;= 2^{3}A(2^{m-3}+(b_{m-1}b_{m-2}\cdots b_{3})_2)\\\\
&amp;= \cdots
\end{align}
$$
</div>


<p>At each iteration, whether $b_i$ is $0$ or $1$, we can ignore it when
dividing by $2$. And as $2^m &lt; l$, it takes no more than $m$ steps
(removing the $m$ bits $b_0$ to $b_{m-1}$) to reduce $A(2^m+l)$ to
$2^mA(1) = 2^m$</p>

<h2>Radix-based Generalised Josephus Solution</h2>

<p>The equation 1.18:</p>

<p>$$f \left( ( b_m b_{m-1} \cdots b_1 b_0)_d \right) = \left( \alpha_{b_m} \beta_{b_{m-1}} \beta_{b_{m-2}} \cdots \beta_{b_1} \beta_{b_0} \right)_c$$</p>

<p>is so unnaturally smart and simple that I thought the proof must be
missing. But in fact it is indeed trivial, and just as the book
states, follows from the rewriting of the argument in base $d$, then
recurrence over $m$ (with $m$ the number of digits or the argument in
base $d$).</p>

<p>In the next post in this series, I will start the exercises.</p>
]]></content>
  </entry>
  
</feed>
