<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Mathematics | Wakatta!]]></title>
  <link href="http://blog.wakatta.jp/blog/categories/mathematics/atom.xml" rel="self"/>
  <link href="http://blog.wakatta.jp/"/>
  <updated>2012-01-09T19:30:18+09:00</updated>
  <id>http://blog.wakatta.jp/</id>
  <author>
    <name><![CDATA[Frédéric Dumont]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Concrete Mathematics Chapter 1 Homework Exercises Part 1]]></title>
    <link href="http://blog.wakatta.jp/blog/2012/01/09/concrete-mathematics-chapter-1-homework-exercises-part-1/"/>
    <updated>2012-01-09T20:23:00+09:00</updated>
    <id>http://blog.wakatta.jp/blog/2012/01/09/concrete-mathematics-chapter-1-homework-exercises-part-1</id>
    <content type="html"><![CDATA[<p>I am working my way through the homework exercises, and so far I have
had more success than with the warmups. Here's what I have solved so far.</p>

<!--more-->


<h2>Homework Exercises</h2>

<h3>Basic recurrence</h3>

<p>This one was fairly simple, so simple that I wasted one hour trying to
improve the solution.</p>

<p>Just computing the first few terms of the sequence:</p>

<div markdown="0">
\begin{align}
Q_0 &amp; = \alpha \\\\
Q_1 &amp; = \beta \\\\
Q_2 &amp; = \frac{1+\beta}{\alpha}\\\\
Q_3 &amp; = \frac{1+\alpha+\beta}{\alpha\beta}\\\\
Q_4 &amp; = \frac{\alpha\left( 1 + \alpha + \alpha\beta + \beta\right)}{\alpha\beta(1+\beta)}\\\\
&amp; = \frac{(1+\alpha)(1+\beta)}{\beta(1+\beta)}\\\\
&amp; = \frac{1+\alpha}{\beta}\\\\
Q_5 &amp; = \frac{\alpha\beta\left(1+\alpha+\beta \right)}{\beta \left( 1+\alpha+\beta \right)}\\\\
&amp; = \alpha\\\\
Q_6 &amp; = \frac{\beta\left( 1+\alpha \right)}{1+\alpha}\\\\
&amp; = \beta
\end{align}
</div>


<p>So the sequence is cyclic. I tried to find a closed formula, but the
book does not go that far, and it is unlikely to be possible.</p>

<h3>Product of averages</h3>

<h4>$P(n)$ implies $P(n-1)$</h4>

<p>First of all, I checked that nothing fishy was going on with the
selection of a particular $x_n$, but if $P(n)$ is true, then it is
true for every $x_1\cdots x_n$ set, and in particular for one with a
specific $x_n$.</p>

<p>So nothing fishy is going on.</p>

<p>Assuming the given value for $x_n$, we have</p>

<div markdown="0">
\begin{align}
\left( \frac{x_1 + \cdots + x_n}{n} \right)^n &amp; = \left( \frac{x_1 + \cdots + x_{n-1} + \frac{x_1+\cdots+x_{n-1}}{n-1}}{n}\right)^n\\\\
&amp; = \left( \frac{(n-1)x_1 + \cdots + (n-1)x_{n-1}+x_1+\cdots + x_{n-1}}{n(n-1)}\right)^n\\\\
&amp; = \left( \frac{n(x_1+\cdots+x_{n-1})}{n(n-1)}\right)^n\\\\
&amp; = \left( \frac{x_1+\cdots+x_{n-1}}{n-1}\right)^n\\\\
&amp; = x_n^n
\end{align}
</div>


<p>So, assuming $P(n)$, we have</p>

<div markdown="0">
\begin{align}
x_1\cdots x_{n-1}x_n &amp;\le x_n^n\\\\
x_1\cdots x_{n-1} &amp;\le x_n^{n-1}\\\\
x_1\cdots x_{n-1} &amp;\le \left( \frac{x_1+\cdots+x_{n-1}}{n-1}\right)^{n-1}&amp;&amp;\text{i.e. $P(n-1)$}
\end{align}
</div>


<h4>$P(n)$ and $P(2)$ implies $P(2n)$</h4>

<div markdown="0">
\begin{align}
x_1\cdots x_{2n} &amp; = x_1\cdots x_{n}x_{n+1}\cdots x_{2n}&amp;&amp;\text{associativity}\\\\
&amp; \le \left(\frac{x_1+\cdots+x_n}{n}\right)^n \left(\frac{x_{n+1}+\cdots+x_{2n}}{n}\right)^n&amp;&amp;\text{applying $P(n)$ twice}\\\\
&amp; = \left( \frac{x_1+\cdots+x_n}{n}\frac{x_{n+1}+\cdots+x_{2n}}{n}\right)^n\\\\
&amp; \le \left( \left(\frac{\frac{x_1+\cdots+x_n}{n} + \frac{x_{n+1}+\cdots+x_{2n}}{n}}{2} \right)^2\right)^n&amp;&amp;\text{applying $P(2)$}\\\\
&amp; = \left( \frac{x_1+\cdots+x_n+x_{n+1}+\cdots+x_{2n}}{2n}\right)^{2n}&amp;&amp;\text{i.e. $P(2n)$}\\\\
\end{align}
</div>


<h4>$P(n) \forall n \ge 1$</h4>

<p>The case for $P(1)$ is trivial, and $P(2)$ is already proven. We have
$P(n)$ implies $P(n-1)$ and $P(n)$ implies $P(2n)$.</p>

<p>One first approach is to use the basic induction step: we have $P(1)$,
$P(2)$, and we need $P(n) \implies P(n+1)$.</p>

<p>But $P(n) \implies P(2n) \implies P(2n-1) \implies \cdots \implies
P(2n-(n-1))$. The last one is $P(n1+)$, so the induction step holds.</p>

<p>Alternatively, we can show that to prove $P$ for a given $n$, we need
to prove $P$ for a smaller value. As naturals have a minimum, we must
eventually rely on $P(2)$, which would prove the whole chain.</p>

<p>To see this, for $n \ge 3$, if $n = 2m$, we need to prove $P(m)$; if
$n = 2m+1$, we need to prove $P(2m+2)$, which is implied by $P(m+1)$.</p>

<p>So, $\forall n \ge 3, \exists m \lt n \mid P(m) \implies P(n)$. That
with the base cases is enough to establish $P(n) \forall n$.</p>

<h3>Clockwise Tower of Hanoi</h3>

<p>First, both $Q_0$ and $R_0$ are trivial.</p>

<p>Then, to move $n$ discs from $A$ to $B$, you need to move $n-1$ discs
from $A$ to $C$ (counter-clockwise), then move one disc from $A$ to
$B$, then move the $n-1$ discs from $C$ to $B$ (again,
counter-clockwise).</p>

<p>This means $Q_n = R_{n-1} + 1 + R_{n-1} = 2R_{n-1} + 1$.</p>

<p>The case for $R_n$ is a bit more complex. My first (flawed) attempt
was to observe that to move $n$ discs from $B$ to $A$, you could move
them from $B$ to $C$, then $C$ to $A$. In other words,</p>

<div markdown="0">
\begin{align}
R_n &amp; \ge 2Q_n\\\\
&amp; = Q_n + 2R_{n-1} + 1&amp;&amp;\text{Replacing one \(Q_n\) by \(2R_{n-1}+1\)}\\\\
&amp; = Q_n + 4Q_{n-1} + 1&amp;&amp;\text{Replacing \(R_{n-1}\) by \(2Q_{n-1}\)}\\\\
\end{align}
</div>


<p>But the $4Q_{n-1}$ means moving the stack of $n-1$ discs $4$ times,
which is the same as moving it just one time (as $3$ times bring it
back to its original position).</p>

<p>So we're left with just $Q_n + Q_{n-1} + 1$. But as I said, this
reasoning is flawed, as it mixes the count of moves with the effect of
moves (where $3$ moves are the same as $0$ move).</p>

<p>While it is possible to repair this reasoning by introducing special
operators that take two parameters (the number of discs, and the
number of steps), it is simpler to try and express $R_n$ strictly in
terms $n-1$ stacks and $1$ disc moves.</p>

<p>So, to move $n$ discs from $B$ to $A$, you need to move $n-1$ discs
from $B$ to $A$ (counter-clockwise), then one disc from $B$ to $C$
(clockwise), then the $n-1$ discs from $A$ to $B$ (clockwise), then
one disc from $C$ to $A$ (clockwise), then finally the $n-1$ discs
from $B$ to $A$ (counter-clockwise).</p>

<p>Or,</p>

<div markdown="0">
\begin{align}
R_n &amp;= R_{n-1} + 1 + Q_{n-1} + 1 + R_{n-1}\\\\
&amp; = 2R_{n-} + 1 + Q_{n-1} + 1\\\\
&amp; = Q_n + Q_{n-1} + 1&amp;&amp;\text{definition of \(Q_n\)}\\\\
\end{align}
</div>


<p>As the recurrence is expressed (initially) only in terms of necessary
moves of strictly smaller stacks, there is no risk of hiding moves
that are equivalent to no moves (as in my first attempt), so the
equation is the minimum number of moves.</p>

<h3>Double Tower of Hanoi</h3>

<h4>Basic Problem</h4>

<p>First, notice we should keep each pair together, because otherwise
they would block larger discs from moving. So each pair of move should
be used to relocate a pair of identical discs to another peg. So we
should expect to need twice as many moves as the original tower.</p>

<p>More precisely, with $A(n)$ the number of moves required to solve a
$2n$ Double Tower of Hanoi, we have:</p>

<div markdown="0">
\begin{align}
(1) &amp; = 2\\\\
A(n) &amp; = A(n-1) + 2 + A(n-1)\\\\
&amp; = 2A(n-1) + 2\\\\
\end{align}
</div>


<p>Using $A(n) + 2= U(n)$, we get</p>

<div markdown="0">
\begin{align}
U(1) &amp; = 4\\\\
U(n) &amp; = 2U(n-1)\\\\
&amp; 2^{n+1}\\\\
A(n) &amp; = 2^{n+1} -2\\\\
     &amp; = 2(T_n)\\\\
\end{align}
</div>


<h4>Order Preserving</h4>

<p>If we consider all the $2n$ discs as different, then in $T_{2n}=2^{2n}-1$
moves, we can recreate the same order as the original.</p>

<p>Of course, we can do better. It is enough to move each pair an even
number of times: the first time will switch their order; the second
one will restore it, ...</p>

<p>This is similar to the warmup problem where we cannot move any disc
directly between any two pegs, so using the same constraint to move
any pair would get us to the target order in less than $2\cdot 3^n-1$.</p>

<p>But there is still a better way.</p>

<p>A $2$ discs problem needs exactly $3$ moves.  And the $4$ discs
problem will require just $11$ moves, rather than the $18$ that the
above formula predicts.</p>

<p>A wild guess: the number of moves is $4(2^n-1)-1$.</p>

<p>In trying to solve (or even write) the recurrence equation, it is
important to keep in mind that several ways to move the discs, each
with its own count, will be used.</p>

<p>We know we need two pairs of moves to relocate the two bottom discs
while keeping the order (assuming there are other discs). In doing so,
we will move the next two discs an even number of times, requiring
another 2 times to keep their order. So as long as we make sure the
last operation has the right (even) number of moves, we do not need to
keep this constraint on the other operations.</p>

<p>To recap: we need to move the last pair of discs $2$ times. So we first move
the $n-1$ pairs to a peg, then move the last pair to the other peg,
then the $n-1$ pairs to the first peg, then the last pair to the last
peg. At this stage, the $n-1$ discs have move an even number of times,
so their in the right order, even if we used the non order preserving
solution that was computed above (requiring $2T_{n-1}$ moves).</p>

<p>At this stage, a bit of notation should clarify:</p>

<div markdown="0">
\begin{align}
B(1) &amp; = 3\\\\
B(n) &amp; = A(n-1) + 2 + A(n-1) + 2 + B(n-1)\\\\
&amp; = 2T_{n-1} + 2 + 2T_{n-1} + 2 + B(n-1)\\\\
&amp; = 4T_{n-1}+4+B(n-1)\\\\
\end{align}
</div>


<p>Trying to prove the guess above:</p>

<div markdown="0">
\begin{align}
B(1) &amp; = 4(2^1-1) - 1\\\\
&amp; = 3\\\\
B(n) &amp; = 4(2^{n-1} -1) + 4 + B(n-1)\\\\
&amp; = 4\cdot 2^{n-1} + 4(2^{n-1} - 1) -1\\\\
&amp; = 4\cdot 2^n -4 -1\\\\
&amp; = 4(2^n-1)-1
\end{align}
</div>


<p>So the guess was right. It can also be rewritten as</p>

<div markdown="0">
\begin{align}
4(2^n-1)-1 &amp = 4\cdot 2^n - 4 -1\\\\
&amp; = 2^{n+2} - 5\\\\
\end{align}
</div>


<p>which is the book solution.</p>

<p>This being a bonus exercise, I currently experience an intense, although
pointless, sense of pride and achievement.</p>

<p>No doubt the other exercises will cut me down to size.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Concrete Mathematics Chapter 1 Warmups]]></title>
    <link href="http://blog.wakatta.jp/blog/2012/01/07/concrete-mathematics-chapter-1-warmups/"/>
    <updated>2012-01-07T19:09:00+09:00</updated>
    <id>http://blog.wakatta.jp/blog/2012/01/07/concrete-mathematics-chapter-1-warmups</id>
    <content type="html"><![CDATA[<p>It took me far longer than it should have, and I had a very partial
success; I guess my excuse is that my brain was still cold...</p>

<p>At least I can claim I did try to solve all the exercises; I really
spent hours on this.</p>

<!--more-->


<h2>Warmups</h2>

<h3>Horse colour</h3>

<p>I kind of botched this one, as I tried to answer it even before
reading the chapter... and my first instinct was that such a use of
induction (taking numbered subsets) was invalid.</p>

<p>Of course it is not. This is a perfectly valid approach, but, as the
book states, in the present case it breaks down for $n=2$.</p>

<p>Properly expressed with math notation, it becomes clear that the
``same colour'' concept is a binary relation (a reflexive, symmetric
and transitive one). The key is <em>binary</em>: if every pair of horses were
the same colour, then induction could be used.</p>

<h3>Tower of Hanoi Variation</h3>

<p>The description in the book is somewhat confusing, as it states the
restriction in terms of absolute positions (that is, no direct move
between left peg and right peg), rather than relative (if you want to
move a disc between peg $A$ and peg $B$, you must first move it to peg $C$,
then to peg $B$).</p>

<p>The first approach does not work (that is, it is impossible to solve
the problem under these conditions), but obviously the authors meant
the second approach.</p>

<h4>Number of moves</h4>

<p>This variation can be solved using the exact same tools as the
original problem.</p>

<p>Assuming we want to move a stack from $A$ to $B$, using $C$ as
transfer peg: a single disc can be moved in $2$ steps ($A$ to $C$, $C$
to $B$); to move more than $1$, you first need to move the $n-1$ from
$A$ to $B$, then move $1$ disk from $A$ to $C$, move the $n-1$ discs
from $B$ back to $A$, move the one disc from $C$ to $B$, and finally
move the $n-1$ discs from $A$ to $B$.</p>

<p>More concisely:</p>

<div markdown="0">
$$
\begin{align}
T_1 &amp;= 2&amp;&amp;\text{base case}\\\\
T_n &amp;= T_{n-1} + 1 + T_{n-1} + 1 + T_{n-1}\\\\
&amp; = 3T_{n-1} + 2&amp;&amp;\text{recurrence equation}
\end{align}
$$
</div>


<p>Using the exact same method as in the book, let's define
$T_n + 1= U_n$:</p>

<div markdown="0">
$$
\begin{align}
U_1 &amp;= T_1 + 1\\\\
&amp; = 3\\\\
U_n &amp;= T_n + 1\\\\
&amp; = 3(U_{n-1} -1) + 3\\\\
&amp; = 3U_{n-1} - 3 + 3\\\\
&amp; = 3U_{n-1}
\end{align}
$$
</div>


<p>Then, $U_n = 3^n$, and $T_n = 3^n-1$.</p>

<h4>Arrangements</h4>

<p>As discs must be sorted, to describe an arrangement it is enough to
list the peg for each disc. As there are $3$ pegs, this means
there are $3^n$ different arrangements.</p>

<p>The variation takes $3^n-1$ moves, but counting the starting position
as well, this means $3^n$ different positions, which is the same as
the total number of arrangements.</p>

<h3>Tower of Hanoi, Initial Setup Variation</h3>

<p>Once again, by induction: to move a disk to peg $B$:</p>

<p><em>Base case</em>: moving the smallest disc takes at most $1$ move ($0$ if
it is already on peg $B$), so $T_1 \le 1$;
<em>Recurrence</em>: to move the disc of size $n$, assuming it is on $A$, we
need to move all the smaller discs to $C$ (to clear both $A$ and $B$),
then move the disc of size $n$, and finally move all the smaller discs
to $B$. Calling the clearing operation $Cl_n$, we have
$T_n \le Cl_{n-1} + 1 + T_{n-1}$.</p>

<p>A moment of thought is enough to realise that $Cl_n$ amounts to the
same operation as $T_n$ (that is, move each disc to a specific peg,
no matter where it currently is), so we have $Cl_n = T_n$, and
therefore $T_n \le 2T_{n-1} + 1$, which is the same recurrence equation
as the original problem.</p>

<p>Therefore there is no position that is more that $2^n-1$ moves from
the target position.</p>

<h3>Venn Diagram with 4 circles</h3>

<p>I completely failed to solve this one, even though I spent most of the
time on this problem alone. I had the intuition that it could not be
done; I also found that the maximum number of regions would be 14, but
not matter what I tried, I could not prove it.</p>

<p>I tried to use Geometry, hoping that a minimal list of constraints on
the circles would prove that some of the regions that should be
restricted to two circles were in fact always covered by three or
more.</p>

<p>Eventually, when I gave up and looked at the solution, I still could not
understand it. So a circle can only intersect another one in at most 2
points. OK, so what?</p>

<p>After more research (the Google kind, this time), I found
<a href="http://www.brynmawr.edu/math/people/anmyers/PAPERS/Venn.pdf">this paper</a>
which explains why. Each intersection point creates a single new
region. Although once again I have no intuition I can trust in this
domain, in this case the reasoning seems similar enough to
intersecting lines that I feel somewhat confident.</p>

<p>So the above observation gives a recurrence equation:</p>

<div markdown="0">
$$
\begin{align}
C_1 &amp;= 2\\\\
C_n &amp;= C_{n-1} + 2(n-1)
\end{align}
$$
</div>


<p>Already, we have that $C_4 = 14$, which is less than the required
$16$ for a Venn diagram (and according to this
<a href="http://www.combinatorics.org/Surveys/ds5/VennEJC.html">document</a>),
four circles form a <em>Euler diagram</em>, not a Venn diagram.</p>

<p>Clearly a triangular number sequence is hiding in there. The
recurrence equations above can be rewritten as</p>

<div markdown="0">
$$
\begin{align}
C_n &amp;= 2+\sum_{i=1}^{n}2(i-1)\\\\
&amp;= 2+2\sum_{i=0}^{n-1}i\\\\
&amp;= 2+2\frac{n(n-1)}{2}\\\\
&amp;= n^2-n+2
\end{align}
$$
</div>


<h3>Bounded Regions in the Plane</h3>

<p>Another one where my intuition for Geometry completely failed me. I
had a correct start, identifying that each new line intersecting the
existing ones at $k$ points could at best create $k-1$ new bounded
regions, but when I try to check this I fumbled.</p>

<p>Yet the reason it simple: a line intersecting 2 others will either
define a bounded triangle, or cut an existing bounded region in two.</p>

<p>The new bounded regions are not made of arbitrary triple of lines, but
are next to each others in the plane; really this is similar to the
fence problem. So a line cutting $k$ other lines will create at best
$k-1$ new bounded region. The equality is achieved if there are no
parallel lines, and all the intersection points are distinct.</p>

<p>As the book observes, each new line will also add two new unbounded
regions (the original problem had that a new line would create
$k+1$ new regions).</p>

<p>Once again, the triangular number sequence is not far:</p>

<div markdown="0">
$$
\begin{align}
B_i &amp; = 0 &amp;&amp\text{for $1 \\le i \\lt 3$}\\\\
B_3 &amp; = 1\\\\
B_n &amp; = B_{n-1} + n - 2\\\\
&amp; = \sum_{i=2}^{n} i-2\\\\
&amp; = \sum_{i=0}^{n-2} i\\\\
&amp; = \frac{(n-1)(n-2)}{2}\\\\
&amp; = S_{n-2}
\end{align}
$$
</div>


<h3>Invalid Recurrence</h3>

<p>The recurrence for $H$ has a number of problems. The one I found is
that it only establishes the induction hypothesis for going from an
even number to an odd one; nothing can be said for going from an odd
number to an even one (and indeed, the hypothesis breaks then).</p>

<p>As the book mentions, another problem is the base case, which is
incompatible with the induction hypothesis.</p>

<h3>Wrapping up</h3>

<p>I spent way too much time on these exercises, but most of it was on
exercises with a geometric nature: I could not find an algebraic
description of these problems that would be suitable for the kind of
treatment this chapter is about. But once I had the equations, I was
able to solve the problems without trouble.</p>

<p>Next, the homework exercises.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Concrete Mathematics Chapter 1 Notes]]></title>
    <link href="http://blog.wakatta.jp/blog/2012/01/06/concrete-mathematics-chapter-1-notes/"/>
    <updated>2012-01-06T13:52:00+09:00</updated>
    <id>http://blog.wakatta.jp/blog/2012/01/06/concrete-mathematics-chapter-1-notes</id>
    <content type="html"><![CDATA[<p>For the first post of this hopefully long series, I have a few notes I
wrote down as I was reading Chapter 1. Nothing revolutionary, but it
gives me a chance to play with math notation.</p>

<!--more-->


<h1>Lines in the Plane</h1>

<p>I must admit that my memories of Geometry are far, far away (the
subject was not addressed at all when I studied Mathematics at
university, and I had no need for Geometry in my work since), so I
spent perhaps an unreasonable amount of time to check the validity of
the most elementary steps.</p>

<p>It goes without saying that the exercises of a Geometric nature are
particularly challenging (as if I needed the extra difficulty).</p>

<h2>Intersecting lines</h2>

<p>The notion that one line will add $k$ new regions if it intersects
other lines at $k-1$ points is due to the fact that $k-1$ distinct
lines define at least $k$ regions (more if they are not all parallel),
and one more line that intersects them all will divide these $k$
regions in two.</p>

<h1>Josephus Problem</h1>

<h2>$J(5 \cdot 2^m) = 2^{m+1} + 1$</h2>

<p>This is based on the fact that $J(10) = 5$ and $J(2n) = 2J(n) -1$.</p>

<p>By induction:</p>

<p><em>Base case</em>: it is true for $m = 1$: $J(5\cdot 2) = J(10) = 5 =
2^{1+1} + 1$</p>

<p><em>Recurrence</em>: assuming it is true for $m$,</p>

<div markdown="0">
$$
\begin{align}
J(5\cdot 2^{m+1}) &amp;= J(2(5\cdot 2^m))\\\\
&amp;= 2J(5\cdot 2^m) - 1&amp;&amp;\text{as $J(2n) = 2J(n) -1$}\\\\
&amp;= 2(2^{m+1}+1) - 1&amp;&amp;\text{induction hypothesis}\\\\
&amp;= 2\cdot 2^{m+1} + 2 - 1\\\\
&amp;= 2^{m+2} + 1
\end{align}
$$
</div>


<h2>$A(2^{m}+l) = 2^{m}$</h2>

<p>It took me a while to convince myself that the $l$ was not a problem
here. This can be seen by considering $l$ in binary notation, and
using $A(2n) = 2A(n)$ and $A(2n+1) = 2A(n)$ to remove the rightmost
bit.</p>

<p>That is, with $2^m > l = (b_{m-1}b_{m-2}\cdots b_{1}b_{0})_2$,we have:</p>

<div markdown="0">
$$
\begin{align}
A(2^{m}+l) &amp;= A(2^{m}+(b_{m-1}b_{m-2}\cdots b_{1}b_{0})_2)\\\\
&amp;= 2A(2^{m-1}+(b_{m-1}b_{m-2}\cdots b_{1})_2)\\\\
&amp;= 2^{2}A(2^{m-2}+(b_{m-1}b_{m-2}\cdots b_{2})_2)\\\\
&amp;= 2^{3}A(2^{m-3}+(b_{m-1}b_{m-2}\cdots b_{3})_2)\\\\
&amp;= \cdots
\end{align}
$$
</div>


<p>At each iteration, whether $b_i$ is $0$ or $1$, we can ignore it when
dividing by $2$. And as $2^m &lt; l$, it takes no more than $m$ steps
(removing the $m$ bits $b_0$ to $b_{m-1}$) to reduce $A(2^m+l)$ to
$2^mA(1) = 2^m$</p>

<h2>Radix-based Generalised Josephus Solution</h2>

<p>The equation 1.18:</p>

<p>$$f \left( ( b_m b_{m-1} \cdots b_1 b_0)_d \right) = \left( \alpha_{b_m} \beta_{b_{m-1}} \beta_{b_{m-2}} \cdots \beta_{b_1} \beta_{b_0} \right)_c$$</p>

<p>is so unnaturally smart and simple that I thought the proof must be
missing. But in fact it is indeed trivial, and just as the book
states, follows from the rewriting of the argument in base $d$, then
recurrence over $m$ (with $m$ the number of digits or the argument in
base $d$).</p>

<p>In the next post in this series, I will start the exercises.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Concrete Mathematics]]></title>
    <link href="http://blog.wakatta.jp/blog/2012/01/06/concrete-mathematics/"/>
    <updated>2012-01-06T13:16:00+09:00</updated>
    <id>http://blog.wakatta.jp/blog/2012/01/06/concrete-mathematics</id>
    <content type="html"><![CDATA[<p>Stephen Hawking once said that his editor had warned him that each
equation in his book would halve the readership.</p>

<p>With that in mind, and taking into account the number of readers of
this blog (or lack thereof), would I dare put any equations?</p>

<p>You better believe it!</p>

<!--more-->


<p>I just picked up my old copy of
<a href="http://en.wikipedia.org/wiki/Concrete_Mathematics">Concrete Mathematics</a>,
a book I have too long neglected. The ultimate goal, of course, is
slaying the
<a href="http://en.wikipedia.org/wiki/The_Art_of_Computer_Programming">Beast</a>,
which I should try to complete before Donald E. Knuth passes away.
While I wish him a very long life, long enough at least to complete
<a href="http://en.wikipedia.org/wiki/The_Art_of_Computer_Programming#Volumes">Volume 5</a>,
and better yet 6 and 7, I should not take his remarkable health as an
excuse to dither.</p>

<p>For the math notation, I use <a href="http://www.mathjax.org/">MathJax</a>, a
JavaScript library that can parse either
<a href="http://www.w3.org/Math/">MathMl</a>, or much better
<a href="http://www.latex-project.org/">LaTeX</a> (which is based on
<a href="http://www.math.upenn.edu/TeX.html">TeX</a>, another gift of Donald
E. Knuth to the world).</p>

<p>The setup for this blog is based on this
<a href="http://greglus.com/blog/2011/11/29/integrate-MathJax-LaTeX-and-MathML-Markup-in-Octopress/">post</a>.</p>

<p>The quality of rendering is variable: pretty good in Firefox, OK in
Safari or Chrome, and no idea in IE or Opera. Of course, it is not as
good as the output of LaTeX, but for the Web it is acceptable.</p>

<p>For instance, given the recurrence</p>

<div markdown="0">
$$
\begin{align}
f(j) &amp; = \alpha_j, &amp;&amp;\text{for $1 \\leq j \\lt  d$}\\\\
f(dn + j) &amp; = cf(n) + \beta_j, &amp;&amp;\text{for $0 \\leq j \\lt d$ and $n \\geq 1$}
\end{align}
$$
</div>


<p>then the solution is</p>

<p>$$f \left( ( b_m b_{m-1} \cdots b_1 b_0)_d \right) = \left( \alpha_{b_m} \beta_{b_{m-1}} \beta_{b_{m-2}} \cdots \beta_{b_1} \beta_{b_0} \right)_c$$</p>

<p>(refer to the book for explanations).</p>

<p>Isn't this lovely?</p>
]]></content>
  </entry>
  
</feed>
